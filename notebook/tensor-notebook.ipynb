{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('../')\n",
    "from tensor_factorization import initialize_factorization, D, fine_tune, Lambda\n",
    "from tensor_factorization import evaluate\n",
    "from FactorizationRatingsAprox import FactorizationRatingsAprox\n",
    "from split_data import split_data\n",
    "from sparse_array import NDSparseArray\n",
    "from datetime import datetime\n",
    "# setting path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_path = \"../factorization_movies_model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_path = \"../datasets/movies/ratings_small.csv\"\n",
    "train_path = \"../datasets/movies/ratings_small_train.csv\"\n",
    "test_path = \"../datasets/movies/ratings_small_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_data(dataset_path, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([(472, 2470, 4. ,  944321548), (150, 1198, 4. , 1114306013),\n       (624, 2369, 3. , 1019128415), ( 19,  379, 3. ,  855193845),\n       (450, 2542, 4.5, 1475737111), (362, 1208, 3.5, 1218567130)],\n      dtype=[('f0', '<i4'), ('f1', '<i4'), ('f2', '<f4'), ('f3', '<i4')])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load csv\n",
    "train_data = np.loadtxt(train_path, delimiter=\",\", skiprows=0, dtype=\"i4,i4,f,i4\")\n",
    "test_data = np.loadtxt(test_path, delimiter=\",\", skiprows=0, dtype=\"i4,i4,f,i4\")\n",
    "all_data = np.loadtxt(dataset_path, delimiter=\",\", skiprows=1, dtype=\"i4,i4,f,i4\")\n",
    "train_data[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the data\n",
    "def transform_data(data):\n",
    "    # Put timestamps into \"bins\" of year and month only\n",
    "    _timestamps = [line[3] for line in data]\n",
    "    _timestamps = [datetime.fromtimestamp(timestamp) for timestamp in _timestamps]\n",
    "    _timestamps = [(timestamp.year-1995)*12+timestamp.month for timestamp in _timestamps]\n",
    "    # _timestamps = [timestamp.hour for timestamp in _timestamps]\n",
    "\n",
    "    # Load user Ids and movieIds\n",
    "    _user_ids = [line[0] for line in data]\n",
    "    _movie_ids = [line[1] for line in data]\n",
    "    _ratings = [line[2] for line in data]\n",
    "\n",
    "    return _user_ids, _movie_ids, _ratings, _timestamps\n",
    "\n",
    "def make_sparse(_SP, _Y_shape):\n",
    "    _user_ids, _movie_ids, _ratings, _timestamps = _SP\n",
    "    # Create sparse array\n",
    "    Y = NDSparseArray(_Y_shape)\n",
    "    for i in range(len(_user_ids)):\n",
    "        Y[_user_ids[i], _movie_ids[i], _timestamps[i]] = _ratings[i]\n",
    "\n",
    "    return Y\n",
    "\n",
    "user_ids, movie_ids, ratings, timestamps = transform_data(all_data)\n",
    "Y_shape = [max(user_ids) + 10, max(movie_ids) + 1, max(timestamps) + 1]\n",
    "Y = make_sparse(transform_data(train_data), Y_shape)\n",
    "Y_test = make_sparse(transform_data(test_data), Y_shape)\n",
    "Y[564, 1831, 71]  # 71 = (2000-1995) * 12 + 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create new matrices for factorization\n",
    "U, M, C, S = initialize_factorization(Y, D(20, 50, 5), Lambda(0.1, 0.1, 0.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define average error functon\n",
    "def get_mae(_U, _M, _C, _S, _Y_test: NDSparseArray):\n",
    "    error_sum = 0\n",
    "    n = len(_Y_test.elements)\n",
    "    for i, j, k in _Y_test.indexes():\n",
    "        rating = _Y_test[i, j, k]\n",
    "        evalRating = evaluate(_U, _M, _C, _S, i, j, k)\n",
    "        error = abs(rating - evalRating)\n",
    "        error_sum += error\n",
    "    MAE = error_sum / n\n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7136140268383545 99003/99003     \n",
      "Train:  0.6763020457318929\n",
      "Test:  0.7255363793853257\n",
      "0.6927259372758419 99003/99003     \n",
      "Train:  0.664436973969987\n",
      "Test:  0.7222579349242101\n",
      "0.684305667138462 99003/99003      \n",
      "Train:  0.6605550124565056\n",
      "Test:  0.7312647203412331\n"
     ]
    }
   ],
   "source": [
    "# Train on train dataset\n",
    "la = Lambda(0.000001, 0.0000001, 0.000001, 0.000001)  # Learning rate\n",
    "for t in range(3):\n",
    "    def coef(s):\n",
    "        return 0.01 * 1 / (30 ** 0.5)\n",
    "    U, M, C, S = fine_tune(U, M, C, S, Y, coef, la)\n",
    "    print(\"Train: \", get_mae(U, M, C, S, Y))\n",
    "    print(\"Test: \", get_mae(U, M, C, S, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6792340186429755 99003/99003     \n",
      "Train:  0.6580793004566786\n",
      "Test:  0.7190968772501566\n"
     ]
    }
   ],
   "source": [
    "U, M, C, S = fine_tune(U, M, C, S, Y, coef, la)\n",
    "print(\"Train: \", get_mae(U, M, C, S, Y))\n",
    "print(\"Test: \", get_mae(U, M, C, S, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save this object as FactorizationRatingsAprox pickle\n",
    "new_user_id = Y.shape[0] - 1\n",
    "obj = FactorizationRatingsAprox(U, M, C, S, Y, new_user_id)\n",
    "obj.to_file(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.7190968772501566"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if it is saving corectly\n",
    "obj_load = FactorizationRatingsAprox.from_file(model_path)\n",
    "get_mae(obj_load.U, obj_load.M, obj_load.C, obj_load.S, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2470",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_12500\\1442263426.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[1;33m[\u001B[0m\u001B[1;36m1339\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3.5\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m ]\n\u001B[1;32m---> 12\u001B[1;33m \u001B[0mobj_load\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mratings\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Projects\\Tensor-factorization\\notebook\\..\\FactorizationRatingsAprox.py\u001B[0m in \u001B[0;36mevaluate\u001B[1;34m(self, movie_ratings)\u001B[0m\n\u001B[0;32m     44\u001B[0m         \u001B[0maverage_ratings\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmovie_id\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maverage_ratings\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 46\u001B[1;33m             \u001B[0maverage_ratings\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mmovie_id\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0maverage_ratings\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mmovie_id\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0maverage_ratings\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mmovie_id\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     47\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maverage_ratings\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 2470"
     ]
    }
   ],
   "source": [
    "# Get Top 10 recomendations if these movies were wathched\n",
    "ratings = [\n",
    "    [1029, 3.0],\n",
    "    [1061, 3.0],\n",
    "    [1129, 2.0],\n",
    "    [1172, 4.0],\n",
    "    [1263, 2.0],\n",
    "    [1287, 2.0],\n",
    "    [1293, 2.0],\n",
    "    [1339, 3.5]\n",
    "]\n",
    "obj_load.evaluate(ratings[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d0edb1c3d47766d9e63a049a7f05fa1c03bcedcc5ec271b616e77de6b44b1a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
